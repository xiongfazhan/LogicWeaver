"""AI Analysis Service for step description and materials analysis.

Uses LLM to analyze user's step descriptions and uploaded materials to generate:
- Technical implementation plan for Dify developers
- Model selection and configuration
- Dify node configuration suggestions
"""

import json
import logging
from typing import Optional
from uuid import UUID

from pydantic import BaseModel
from sqlalchemy.orm import Session

from app.models.workflow import WorkflowStep
from app.repositories.step import StepRepository
from app.services.llm import LLMService, LLMServiceError, get_llm_service

logger = logging.getLogger(__name__)


# ============================================================================
# Response Models - Data Flow Specification
# ============================================================================


class DataField(BaseModel):
    """æ•°æ®å­—æ®µå®šä¹‰"""
    name: str               # å­—æ®µåï¼ˆè‹±æ–‡è›‡å½¢å‘½åï¼‰
    type: str               # æ•°æ®ç±»å‹: string, int, float, bool, image, file, list[string], dict ç­‰
    description: str        # å­—æ®µè¯´æ˜ï¼ˆä¸­æ–‡ï¼‰
    required: bool = True   # æ˜¯å¦å¿…å¡«
    example: Optional[str] = None  # ç¤ºä¾‹å€¼


class StepContract(BaseModel):
    """å•ä¸ªæ­¥éª¤çš„æ•°æ®å¥‘çº¦ - Data Flow Specification"""
    step_id: int                      # æ­¥éª¤åºå·
    step_name: str                    # æ­¥éª¤åç§°ï¼ˆä¸­æ–‡ï¼‰
    business_intent: str              # ä¸šåŠ¡æ„å›¾ï¼ˆä¸€å¥è¯è¯´æ¸…æ¥šè¿™ä¸€æ­¥åšä»€ä¹ˆï¼‰
    
    # æ•°æ®å¥‘çº¦
    inputs: list[DataField]           # è¾“å…¥ï¼šè¿™ä¸€æ­¥éœ€è¦ä»€ä¹ˆ
    outputs: list[DataField]          # è¾“å‡ºï¼šè¿™ä¸€æ­¥å¿…é¡»è¿”å›ä»€ä¹ˆ
    
    # å¯é€‰çš„ä¸šåŠ¡è¯´æ˜
    acceptance_criteria: Optional[str] = None  # éªŒæ”¶æ ‡å‡†ï¼ˆæ€æ ·ç®—"åšå¥½äº†"ï¼‰
    notes: Optional[str] = None                # å¤‡æ³¨


class AnalysisResult(BaseModel):
    """AI åˆ†æç»“æœ - Step Contract (æ•°æ®å¥‘çº¦)"""
    contract: StepContract            # æœ¬æ­¥éª¤çš„æ•°æ®å¥‘çº¦
    confidence_score: float           # åˆ†æç½®ä¿¡åº¦


class AnalysisResponse(BaseModel):
    """API response for analysis endpoint."""
    step_id: str
    step_name: str
    result: AnalysisResult
    llm_model: str
    has_materials: bool


# ============================================================================
# Exceptions
# ============================================================================


class AnalysisError(Exception):
    """Base exception for analysis errors."""
    pass


class InsufficientExamplesError(AnalysisError):
    """Raised when there are not enough examples for analysis."""
    pass


class StepNotFoundError(AnalysisError):
    """Raised when step is not found."""
    pass


# ============================================================================
# Analysis Prompt - æ•°æ®å¥‘çº¦å®šä¹‰è€…
# ============================================================================


ANALYSIS_PROMPT_TEMPLATE = """ä½ æ˜¯ä¸€ä¸ª"æ•°æ®å¥‘çº¦å®šä¹‰è€…"ï¼Œè´Ÿè´£å°†ä¸šåŠ¡éœ€æ±‚ç¿»è¯‘æˆ Data Flow Specificationï¼ˆæ•°æ®æµè§„æ ¼è¯´æ˜ä¹¦ï¼‰ã€‚

## ä½ çš„è§’è‰²
- ä¸Šæ¸¸ï¼ˆä¸šåŠ¡äººå‘˜ï¼‰ï¼šåªè´Ÿè´£"æ•™"ï¼ˆç”¨è‡ªç„¶è¯­è¨€æè¿°éœ€æ±‚ï¼‰
- ä½ ï¼ˆå¹³å°ï¼‰ï¼šè´Ÿè´£"è¯‘"ï¼ˆå®šä¹‰æ¸…æ™°çš„æ•°æ®å¥‘çº¦ï¼šInput æ˜¯ä»€ä¹ˆã€Output æ˜¯ä»€ä¹ˆï¼‰
- ä¸‹æ¸¸ï¼ˆå¼€å‘äººå‘˜ï¼‰ï¼šè´Ÿè´£"ç­‘"ï¼ˆæ ¹æ®å¥‘çº¦è‡ªç”±é€‰æ‹©æŠ€æœ¯å®ç°ï¼‰

## æ ¸å¿ƒåŸåˆ™
**ä½ åªå®šä¹‰"è¦ä»€ä¹ˆ"ï¼Œä¸ç®¡"æ€ä¹ˆåš"ã€‚**

ä¾‹å¦‚ï¼š
- âŒ é”™è¯¯ï¼š"ç”¨ YOLOv8 æ£€æµ‹äººæ•°"
- âœ… æ­£ç¡®ï¼š"Input: ä¸€å¼ å›¾ç‰‡ï¼›Output: person_count (int) ä»£è¡¨äººæ•°"

å¼€å‘äººå‘˜çœ‹åˆ°å¥‘çº¦åï¼Œå¯ä»¥è‡ªç”±é€‰æ‹©ï¼š
- ç”¨ YOLO æ£€æµ‹
- ç”¨ GPT-4V è§†è§‰ç†è§£
- ç”šè‡³ç”¨äººå·¥æ ‡æ³¨
åªè¦è¿”å›çš„æ•°æ®æ ¼å¼ç¬¦åˆå¥‘çº¦ï¼Œå°±ç®—åˆæ ¼ã€‚

## æ•°æ®ç±»å‹
å¸¸ç”¨ç±»å‹ï¼š
- `string` - æ–‡æœ¬
- `int` - æ•´æ•°
- `float` - æµ®ç‚¹æ•°
- `bool` - å¸ƒå°”å€¼
- `image` - å›¾ç‰‡ï¼ˆURL æˆ– base64ï¼‰
- `file` - æ–‡ä»¶è·¯å¾„
- `list[string]` - å­—ç¬¦ä¸²åˆ—è¡¨
- `dict` - å­—å…¸/å¯¹è±¡

## è¾“å‡ºæ ¼å¼
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼š
```json
{
  "contract": {
    "step_id": 1,
    "step_name": "æ­¥éª¤ä¸­æ–‡å",
    "business_intent": "ä¸šåŠ¡æ„å›¾ï¼ˆä¸€å¥è¯ï¼‰",
    "inputs": [
      {
        "name": "input_field_name",
        "type": "æ•°æ®ç±»å‹",
        "description": "å­—æ®µè¯´æ˜",
        "required": true,
        "example": "ç¤ºä¾‹å€¼"
      }
    ],
    "outputs": [
      {
        "name": "output_field_name",
        "type": "æ•°æ®ç±»å‹",
        "description": "å­—æ®µè¯´æ˜",
        "required": true,
        "example": "ç¤ºä¾‹å€¼"
      }
    ],
    "acceptance_criteria": "éªŒæ”¶æ ‡å‡†ï¼ˆå¯é€‰ï¼‰",
    "notes": "å¤‡æ³¨ï¼ˆå¯é€‰ï¼‰"
  },
  "confidence_score": 0.9
}
```

## ç¤ºä¾‹

**ç”¨æˆ·è¾“å…¥:** "æ‹ä¸€å¼ åŠå…¬å®¤ç…§ç‰‡"
**è¾“å‡º:**
```json
{
  "contract": {
    "step_id": 1,
    "step_name": "æ‹æ‘„ç…§ç‰‡",
    "business_intent": "é‡‡é›†åŠå…¬å®¤ç°åœºç…§ç‰‡",
    "inputs": [],
    "outputs": [
      {
        "name": "office_image",
        "type": "image",
        "description": "åŠå…¬å®¤ç°åœºç…§ç‰‡",
        "required": true,
        "example": "https://example.com/office.jpg"
      }
    ],
    "acceptance_criteria": "ç…§ç‰‡æ¸…æ™°ï¼Œèƒ½çœ‹æ¸…å®¤å†…å…¨æ™¯",
    "notes": null
  },
  "confidence_score": 0.95
}
```

**ç”¨æˆ·è¾“å…¥:** "æ•°ä¸€ä¸‹æœ‰å‡ ä¸ªäºº"
**è¾“å‡º:**
```json
{
  "contract": {
    "step_id": 2,
    "step_name": "ç»Ÿè®¡äººæ•°",
    "business_intent": "ç»Ÿè®¡å›¾ç‰‡ä¸­çš„äººæ•°",
    "inputs": [
      {
        "name": "office_image",
        "type": "image",
        "description": "ä¸Šä¸€æ­¥æ‹æ‘„çš„åŠå…¬å®¤ç…§ç‰‡",
        "required": true,
        "example": null
      }
    ],
    "outputs": [
      {
        "name": "person_count",
        "type": "int",
        "description": "å›¾ç‰‡ä¸­è¯†åˆ«åˆ°çš„äººæ•°",
        "required": true,
        "example": "5"
      }
    ],
    "acceptance_criteria": "äººæ•°ç»Ÿè®¡è¯¯å·®ä¸è¶…è¿‡1äºº",
    "notes": "å¼€å‘äººå‘˜å¯è‡ªç”±é€‰æ‹©å®ç°æ–¹å¼ï¼ˆCV/VLM/äººå·¥ï¼‰"
  },
  "confidence_score": 0.95
}
```

**ç”¨æˆ·è¾“å…¥:** "æŠŠäººæ•°å¡«åˆ° Excel è¡¨é‡Œ"
**è¾“å‡º:**
```json
{
  "contract": {
    "step_id": 3,
    "step_name": "å†™å…¥è¡¨æ ¼",
    "business_intent": "å°†äººæ•°è®°å½•åˆ° Excel è¡¨æ ¼",
    "inputs": [
      {
        "name": "person_count",
        "type": "int",
        "description": "ä¸Šä¸€æ­¥ç»Ÿè®¡çš„äººæ•°",
        "required": true,
        "example": "5"
      }
    ],
    "outputs": [
      {
        "name": "excel_file",
        "type": "file",
        "description": "æ›´æ–°åçš„ Excel æ–‡ä»¶",
        "required": true,
        "example": "report_2024.xlsx"
      },
      {
        "name": "success",
        "type": "bool",
        "description": "æ˜¯å¦å†™å…¥æˆåŠŸ",
        "required": true,
        "example": "true"
      }
    ],
    "acceptance_criteria": "Excel ä¸­å¯¹åº”å•å…ƒæ ¼å·²æ›´æ–°",
    "notes": null
  },
  "confidence_score": 0.90
}
```

## å…³é”®åŸåˆ™
1. **åªå®šä¹‰å¥‘çº¦ï¼Œä¸å®šæŠ€æœ¯** - ç»ä¸æåŠ YOLO/GPT/Python ç­‰
2. **å˜é‡åç”¨è‹±æ–‡è›‡å½¢å‘½åæ³•** - å¦‚ person_count, office_image
3. **ä¸Šä¸‹æ¸¸è¡”æ¥** - ä¸‹ä¸€æ­¥çš„ input åº”è¯¥èƒ½æ¥ä¸Šä¸€æ­¥çš„ output
4. **ä¸šåŠ¡æ„å›¾æ¸…æ™°** - ç”¨ä¸€å¥è¯è¯´æ¸…æ¥šè¿™ä¸€æ­¥è¦åšä»€ä¹ˆ
"""


class AIAnalysisService:
    """Service for AI-powered step analysis."""

    def __init__(
        self,
        db: Session,
        llm_service: Optional[LLMService] = None,
    ):
        """Initialize analysis service."""
        self.db = db
        self.step_repo = StepRepository(db)
        self.llm = llm_service or get_llm_service()

    def analyze_step_examples(
        self, 
        step_id: UUID,
        previous_outputs: Optional[list[dict]] = None,
    ) -> AnalysisResponse:
        """
        Analyze a step's description and materials.
        
        Args:
            step_id: UUID of the step
            previous_outputs: å‰åºæ­¥éª¤çš„è¾“å‡ºå˜é‡åˆ—è¡¨ï¼Œæ ¼å¼:
                [{"name": "office_image", "type": "image", "description": "..."}]
            
        Returns:
            AnalysisResponse with analysis result
        """
        # Get step
        step = self.step_repo.get_by_id(step_id)
        if not step:
            raise StepNotFoundError(f"Step {step_id} not found")

        # Build analysis input from step data (with context)
        analysis_input = self._build_step_input(step, previous_outputs)
        
        # Check if there's anything to analyze
        # æ£€æŸ¥æ—§å­—æ®µ
        has_old_materials = bool(
            step.context_image_url or 
            step.context_text_content or 
            step.context_voice_transcript
        )
        has_description = bool(
            step.context_description or 
            step.logic_evaluation_prompt
        )
        # æ£€æŸ¥æ–°å­—æ®µï¼šæ•´ç†å¤‡æ³¨å’Œ notes
        has_expert_notes = bool(step.expert_notes)
        has_notes = bool(hasattr(step, 'notes') and step.notes and len(step.notes) > 0)
        
        has_materials = has_old_materials or has_notes
        
        if not has_description and not has_materials and not has_expert_notes:
            # ä»€ä¹ˆéƒ½æ²¡å¡«ï¼Œè¿”å›ç©ºç»“æœ
            return AnalysisResponse(
                step_id=str(step_id),
                step_name=step.name or "æœªå‘½åæ­¥éª¤",
                result=AnalysisResult(
                    contract=StepContract(
                        step_id=0,
                        step_name="æœªé…ç½®",
                        business_intent="æ­¥éª¤æè¿°ä¸ºç©º",
                        inputs=[],
                        outputs=[],
                        acceptance_criteria=None,
                        notes="è¯·å…ˆå¡«å†™æ­¥éª¤æè¿°",
                    ),
                    confidence_score=0.0,
                ),
                llm_model=self.llm.model,
                has_materials=False,
            )
        
        # Call LLM
        try:
            raw_result = self.llm.analyze_text(
                prompt=ANALYSIS_PROMPT_TEMPLATE,
                content=analysis_input,
            )
            
            # Parse result
            result = self._parse_analysis_result(raw_result)
            
            return AnalysisResponse(
                step_id=str(step_id),
                step_name=step.name or "æœªå‘½åæ­¥éª¤",
                result=result,
                llm_model=self.llm.model,
                has_materials=has_materials,
            )

        except LLMServiceError as e:
            logger.error(f"LLM analysis failed: {e}")
            raise AnalysisError(f"AI analysis failed: {e}")

    def _build_step_input(
        self, 
        step: WorkflowStep,
        previous_outputs: Optional[list[dict]] = None,
    ) -> str:
        """Build input text for LLM analysis from step data."""
        parts = []
        
        # ä¸Šä¸‹æ–‡ï¼šå‰åºæ­¥éª¤çš„è¾“å‡ºï¼ˆå¯ç”¨ä½œæœ¬æ­¥éª¤çš„è¾“å…¥ï¼‰
        if previous_outputs:
            context_lines = ["## ä¸Šä¸‹æ–‡ï¼šå‰åºæ­¥éª¤çš„è¾“å‡ºå˜é‡"]
            context_lines.append("ä½ å¯ä»¥åœ¨å®šä¹‰æœ¬æ­¥éª¤çš„ inputs æ—¶ç›´æ¥ä½¿ç”¨è¿™äº›å˜é‡åï¼š")
            for output in previous_outputs:
                name = output.get("name", "unknown")
                dtype = output.get("type", "string")
                desc = output.get("description", "")
                context_lines.append(f"- `{name}` ({dtype}): {desc}")
            context_lines.append("")
            context_lines.append("**æ³¨æ„ï¼šæœ¬æ­¥éª¤çš„ inputs å¦‚æœæ¥è‡ªå‰åºæ­¥éª¤ï¼Œå¿…é¡»ä½¿ç”¨ä¸Šè¿°å˜é‡åï¼**")
            parts.append("\n".join(context_lines))
        
        # Step name
        if step.name:
            parts.append(f"## æ­¥éª¤åç§°\n{step.name}")
        
        # Step description (main content)
        description = step.context_description or step.logic_evaluation_prompt
        if description:
            parts.append(f"## æ­¥éª¤æè¿°\n{description}")
        
        # æ•´ç†å¤‡æ³¨ï¼ˆexpert_notesï¼‰- ä¸“å®¶æ•´ç†çš„è¡¥å……è¯´æ˜
        if step.expert_notes:
            parts.append(f"## æ•´ç†å¤‡æ³¨\n{step.expert_notes}")
        
        # Notes ç´ æï¼ˆä» step_notes è¡¨è·å–ï¼‰
        notes_materials = []
        if hasattr(step, 'notes') and step.notes:
            for note in step.notes:
                if note.content_type == 'image':
                    notes_materials.append(f"- ğŸ“· å›¾ç‰‡ç´ æ: {note.content}")
                elif note.content_type == 'voice':
                    # è¯­éŸ³ï¼šæ˜¾ç¤ºè½¬æ–‡å­—ç»“æœ
                    transcript = note.voice_transcript or "(è¯­éŸ³æœªè½¬æ–‡å­—)"
                    notes_materials.append(f"- ğŸ¤ è¯­éŸ³è½¬æ–‡å­—: {transcript}")
                elif note.content_type == 'text':
                    text = note.content
                    if len(text) > 500:
                        text = text[:500] + "..."
                    notes_materials.append(f"- ğŸ“ æ–‡æœ¬ææ–™:\n{text}")
                elif note.content_type == 'video':
                    notes_materials.append(f"- ğŸ¬ è§†é¢‘ç´ æ: {note.content}")
        
        if notes_materials:
            parts.append("## é‡‡é›†çš„ç´ æ\n" + "\n".join(notes_materials))
        
        # æ—§çš„ææ–™å­—æ®µï¼ˆå…¼å®¹ï¼‰
        old_materials = []
        if step.context_image_url:
            old_materials.append(f"- å›¾ç‰‡ææ–™: {step.context_image_url}")
        if step.context_text_content:
            text = step.context_text_content
            if len(text) > 500:
                text = text[:500] + "..."
            old_materials.append(f"- æ–‡æœ¬ææ–™:\n{text}")
        if step.context_voice_transcript:
            voice = step.context_voice_transcript
            if len(voice) > 500:
                voice = voice[:500] + "..."
            old_materials.append(f"- è¯­éŸ³è½¬å†™:\n{voice}")
        
        if old_materials:
            parts.append("## å‚è€ƒææ–™\n" + "\n".join(old_materials))
        
        return "\n\n".join(parts)

    def _parse_analysis_result(self, raw_result: str) -> AnalysisResult:
        """Parse LLM response into AnalysisResult (æ•°æ®å¥‘çº¦)."""
        try:
            # Extract JSON from response
            if "```json" in raw_result:
                start = raw_result.find("```json") + 7
                end = raw_result.find("```", start)
                json_str = raw_result[start:end].strip()
            elif "```" in raw_result:
                start = raw_result.find("```") + 3
                end = raw_result.find("```", start)
                json_str = raw_result[start:end].strip()
            else:
                json_str = raw_result.strip()
            
            # é¢„å¤„ç†ï¼šä¿®å¤ LLM ç”Ÿæˆçš„æ ¼å¼é”™è¯¯
            # æœ‰æ—¶ LLM ä¼šè¿”å› "example": "{...}" è€Œä¸æ˜¯ "example": {...}
            # æˆ–è€…åµŒå¥— JSON å­—ç¬¦ä¸²ä¸­çš„å¼•å·æ²¡æœ‰è½¬ä¹‰
            import re
            
            # å°è¯•ç›´æ¥è§£æï¼Œå¦‚æœå¤±è´¥åˆ™å°è¯•ä¿®å¤
            try:
                data = json.loads(json_str)
            except json.JSONDecodeError:
                # å°è¯•ä¿®å¤å¸¸è§é—®é¢˜ï¼šå°† "example": åçš„ä¸åˆæ³•å€¼æ›¿æ¢ä¸º null
                fixed_json = re.sub(
                    r'"example"\s*:\s*(?:"?\{[^}]+\}[^,\n]*|"?\[[^\]]+\][^,\n]*|\d+(?:\.\d+)?|true|false)',
                    '"example": null',
                    json_str
                )
                try:
                    data = json.loads(fixed_json)
                    logger.info("Fixed malformed JSON by removing problematic example values")
                except json.JSONDecodeError:
                    # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼ŒæŠ›å‡ºåŸå§‹é”™è¯¯
                    data = json.loads(json_str)
            
            # Parse contract
            contract_data = data.get("contract", {})
            
            # è¾…åŠ©å‡½æ•°ï¼šå°† example è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            def to_str_example(val):
                if val is None:
                    return None
                if isinstance(val, str):
                    return val
                # åˆ—è¡¨ã€æ•°å­—ã€å¸ƒå°”å€¼ç­‰è½¬ä¸º JSON å­—ç¬¦ä¸²
                return json.dumps(val, ensure_ascii=False)
            
            # Parse inputs
            inputs = []
            for field_data in contract_data.get("inputs", []):
                inputs.append(DataField(
                    name=field_data.get("name", "unknown"),
                    type=field_data.get("type", "string"),
                    description=field_data.get("description", ""),
                    required=field_data.get("required", True),
                    example=to_str_example(field_data.get("example")),
                ))
            
            # Parse outputs
            outputs = []
            for field_data in contract_data.get("outputs", []):
                outputs.append(DataField(
                    name=field_data.get("name", "unknown"),
                    type=field_data.get("type", "string"),
                    description=field_data.get("description", ""),
                    required=field_data.get("required", True),
                    example=to_str_example(field_data.get("example")),
                ))
            
            contract = StepContract(
                step_id=int(contract_data.get("step_id", 1)),
                step_name=contract_data.get("step_name", "æœªå‘½åæ­¥éª¤"),
                business_intent=contract_data.get("business_intent", ""),
                inputs=inputs,
                outputs=outputs,
                acceptance_criteria=contract_data.get("acceptance_criteria"),
                notes=contract_data.get("notes"),
            )
            
            return AnalysisResult(
                contract=contract,
                confidence_score=float(data.get("confidence_score", 0.5)),
            )

        except (json.JSONDecodeError, KeyError, ValueError) as e:
            logger.warning(f"Failed to parse LLM response as JSON: {e}")
            # Return a fallback result
            return AnalysisResult(
                contract=StepContract(
                    step_id=0,
                    step_name="è§£æé”™è¯¯",
                    business_intent="LLM å“åº”è§£æå¤±è´¥",
                    inputs=[],
                    outputs=[],
                    acceptance_criteria=None,
                    notes=f"åŸå§‹å“åº”: {raw_result[:200] if raw_result else 'ç©º'}",
                ),
                confidence_score=0.0,
            )
